{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwVxeQppZi28eZbpF3bz4i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/douglasmmachado/MedicineConsumption/blob/main/notebooks/time_series/unified_approach/5_Forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 - Forecasting and prediction"
      ],
      "metadata": {
        "id": "_jKlqIUfCkX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3faZHM1dCq8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "import math as m\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "from subprocess import call\n",
        "from IPython.display import Image\n",
        "\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error,  mean_absolute_percentage_error\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "df_agg_clusters_4_url = \"https://raw.githubusercontent.com/douglasmmachado/MedicineConsumption/main/datasets/time_series/clustered/df_clustered_4.csv\"\n",
        "df_agg_clusters_8_url = \"https://raw.githubusercontent.com/douglasmmachado/MedicineConsumption/main/datasets/time_series/clustered/df_clustered_8.csv\"\n",
        "df_agg_clusters_12_url = \"https://raw.githubusercontent.com/douglasmmachado/MedicineConsumption/main/datasets/time_series/clustered/df_clustered_12.csv\"\n",
        "df_agg_clusters_18_url = \"https://raw.githubusercontent.com/douglasmmachado/MedicineConsumption/main/datasets/time_series/clustered/df_clustered_18.csv\"\n",
        "\n",
        "df_agg_clusters_4 = pd.read_csv(df_agg_clusters_4_url)\n",
        "df_agg_clusters_8 = pd.read_csv(df_agg_clusters_8_url)\n",
        "df_agg_clusters_12 = pd.read_csv(df_agg_clusters_12_url)\n",
        "df_agg_clusters_18 = pd.read_csv(df_agg_clusters_18_url)\n",
        "\n",
        "medicines = ['3400892088310','3400892075761','3400892203645',\n",
        "             '3400892065366','3400892052120','3400891996128',\n",
        "             '3400893826706','3400893736135','3400893875490',\n",
        "             '3400890837149','3400891235203','3400891225037',\n",
        "             '3400891191226','3400892729589','3400892745848',\n",
        "             '3400892697789','3400892761527','3400893022634',\n",
        "             '3400892761695','3400892669236','3400892508566']"
      ],
      "metadata": {
        "id": "R41SXb4cCgUh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_agg_clusters_4.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyTrfeDQxFBK",
        "outputId": "45298c3d-046d-4576-a02a-b42d3e33e2a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2479 entries, 0 to 2478\n",
            "Data columns (total 41 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   index             2479 non-null   int64  \n",
            " 1   HOSPI_CODE_UCD    2479 non-null   int64  \n",
            " 2   QUANTITY          2479 non-null   float64\n",
            " 3   N_UFS             2479 non-null   float64\n",
            " 4   DATE              2479 non-null   object \n",
            " 5   N_ETB             2479 non-null   float64\n",
            " 6   POPULATION        2479 non-null   float64\n",
            " 7   P_MEDICAL         2479 non-null   float64\n",
            " 8   PN_MEDICAL        2479 non-null   float64\n",
            " 9   LIT_HC            2479 non-null   float64\n",
            " 10  LIT_HP            2479 non-null   float64\n",
            " 11  SEJ_MCO           2479 non-null   float64\n",
            " 12  SEJ_HAD           2479 non-null   float64\n",
            " 13  SEJ_PSY           2479 non-null   float64\n",
            " 14  SEJ_SSR           2479 non-null   float64\n",
            " 15  SEJ_SLD           2479 non-null   float64\n",
            " 16  TREND             2479 non-null   float64\n",
            " 17  SEASONAL          2479 non-null   float64\n",
            " 18  RESID             2479 non-null   float64\n",
            " 19  MONTH_1           2479 non-null   int64  \n",
            " 20  MONTH_2           2479 non-null   int64  \n",
            " 21  MONTH_3           2479 non-null   int64  \n",
            " 22  MONTH_4           2479 non-null   int64  \n",
            " 23  MONTH_5           2479 non-null   int64  \n",
            " 24  MONTH_6           2479 non-null   int64  \n",
            " 25  MONTH_7           2479 non-null   int64  \n",
            " 26  MONTH_8           2479 non-null   int64  \n",
            " 27  MONTH_9           2479 non-null   int64  \n",
            " 28  MONTH_10          2479 non-null   int64  \n",
            " 29  MONTH_11          2479 non-null   int64  \n",
            " 30  MONTH_12          2479 non-null   int64  \n",
            " 31  YEAR_2016         2479 non-null   int64  \n",
            " 32  YEAR_2017         2479 non-null   int64  \n",
            " 33  YEAR_2018         2479 non-null   int64  \n",
            " 34  YEAR_2019         2479 non-null   int64  \n",
            " 35  HOSPI_HOSPI_1     2479 non-null   int64  \n",
            " 36  HOSPI_HOSPI_2     2479 non-null   int64  \n",
            " 37  HOSPI_HOSPI_3     2479 non-null   int64  \n",
            " 38  HOSPI_HOSPI_4     2479 non-null   int64  \n",
            " 39  ID_SITE_RATTACHE  2479 non-null   object \n",
            " 40  CLUSTER           2479 non-null   int64  \n",
            "dtypes: float64(16), int64(23), object(2)\n",
            "memory usage: 794.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 - New database composition based on clusters"
      ],
      "metadata": {
        "id": "S8IompnZd1gv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r3PuZvaod6f2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 - Building forecasting models based on clusters"
      ],
      "metadata": {
        "id": "fCyZFkvifBO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pred(y_pred, y_test, medicine):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
        "\n",
        "    # Scatter plot for y_pred\n",
        "    axes[0].scatter(np.arange(len(y_pred)), y_pred, marker='o', label='Predicted', color='blue')\n",
        "\n",
        "    # Scatter plot for y_test\n",
        "    axes[0].scatter(np.arange(len(y_test)), y_test, marker='x', label='Actual', color='red')\n",
        "\n",
        "    # Set axes labels and title\n",
        "    axes[0].set_xlabel('Test samples')\n",
        "    axes[0].set_ylabel('Quantity')\n",
        "    axes[0].set_title(f'Predicted vs Actual: {medicine}')\n",
        "    axes[0].legend()\n",
        "\n",
        "    epsilon = 0.001\n",
        "    mape_array = np.abs(y_test - y_pred) / np.maximum(epsilon, np.abs(y_test))\n",
        "\n",
        "    # Stem plot for MAPE\n",
        "    stem = axes[1].stem(np.arange(len(y_pred)), mape_array, markerfmt='bo', linefmt='b-', basefmt='r-', label='MAPE')\n",
        "    axes[1].set_xlabel('Test samples')\n",
        "    axes[1].set_ylabel('MAPE')\n",
        "    axes[1].set_title(f'MAPE for: {medicine}')\n",
        "    axes[1].set_ylim([0, 1])\n",
        "\n",
        "    mape_target = 0.3\n",
        "    axes[1].axhline(y=mape_target, color='g', linestyle='--', label=f'Target MAPE ({mape_target:.2f})')\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Add a legend\n",
        "    handles, labels = axes[1].get_legend_handles_labels()\n",
        "    axes[1].legend(handles=handles, labels=labels, loc='best')\n",
        "\n",
        "    # Adjust width of subplots and margins\n",
        "    fig.subplots_adjust(wspace=0.4, left=0.1, right=0.9)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7mLsdZ5y6N89"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_1_baseline(df, medicine, df_scores):\n",
        "  print()\n",
        "  print(100*'-')\n",
        "  print('Medicine:' + str(medicine))\n",
        "\n",
        "  X = df[df['HOSPI_CODE_UCD'] == medicine].drop(['QUANTITY', 'HOSPI_CODE_UCD',\n",
        "                                                 'DATE', 'TREND', 'SEASONAL', 'RESID', 'ID_SITE_RATTACHE', 'index'], axis=1).values\n",
        "\n",
        "  y = df[df['HOSPI_CODE_UCD'] == medicine]['QUANTITY'].values\n",
        "\n",
        "  if m.ceil(len(X) * 0.1) == 1:\n",
        "    print('Dataset too small')\n",
        "    test_size = 2\n",
        "  else:\n",
        "    test_size = 0.2\n",
        "\n",
        "  # Split the data into training and testing sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                      test_size = test_size,\n",
        "                                                      random_state = 42)\n",
        "  print(f'Size of data set: {len(X)}')\n",
        "  print(f'Size of training set: {len(X_train)}')\n",
        "  print(f'Size of test set: {len(X_test)}')\n",
        "\n",
        "  # Define the parameter distributions for RandomizedSearchCV\n",
        "  param_grid = {\n",
        "      'max_depth': np.arange(2, 8, 1),\n",
        "      'n_estimators': np.arange(2, max(int(m.ceil(len(X_train)*0.1)),3), 1),\n",
        "      'max_features': ['sqrt', 1, 2]\n",
        "  }\n",
        "  depth_len = param_grid['max_depth'].size\n",
        "  estimators_len = param_grid['n_estimators'].size\n",
        "\n",
        "  print(f'Size of grid search: {depth_len * estimators_len}')\n",
        "\n",
        "  # Create the RandomizedSearchCV object\n",
        "  grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
        "                             param_grid=param_grid,\n",
        "                             scoring = 'neg_mean_absolute_percentage_error',\n",
        "                             cv = 5,\n",
        "                             n_jobs = -1)\n",
        "\n",
        "  ''' >3 : the fold and candidate parameter indexes\n",
        "      are also displayed together with the starting time of the computation.\n",
        "  '''\n",
        "  # Fit the RandomizedSearchCV object to the data\n",
        "  grid_search.fit(X_train, y_train)\n",
        "\n",
        "  # Get the best estimator\n",
        "  best_estimator = grid_search.best_estimator_\n",
        "\n",
        "  # Make predictions using the best estimator\n",
        "  y_pred = best_estimator.predict(X_test)\n",
        "\n",
        "  # Calculate R^2 score\n",
        "  r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "  # Calculate MAE\n",
        "  mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "  # Calculate MAPE\n",
        "  mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "\n",
        "  # Calculate RMSE\n",
        "  rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "  # Print the best parameters, best score, and evaluation metrics\n",
        "  print('Best Parameters: ', grid_search.best_params_)\n",
        "  print('Training Score (MAPE): ', round(grid_search.best_score_, 3))\n",
        "  print(10*'-' + 'Test scores' + 10*'-')\n",
        "  print('R^2 Score:', round(r2, 3))\n",
        "  print('MAE:', round(mae, 3))\n",
        "  print('MAPE:', round(mape, 3))\n",
        "  print('RMSE:', round(rmse, 3))\n",
        "  print()\n",
        "\n",
        "\n",
        "  # Create the new row as a DataFrame\n",
        "  new_row = pd.DataFrame({'HOSPI_CODE_UCD': ['CODE_UCD_'+str(medicine)],\n",
        "                          'R2': [r2],\n",
        "                          'RMSE': [rmse],\n",
        "                          'MAE': [mae],\n",
        "                          'MAPE': [mape]})\n",
        "\n",
        "  # Append the new row to the DataFrame\n",
        "  df_scores = pd.concat([df_scores, new_row], ignore_index=True)\n",
        "\n",
        "  # plot pred x test\n",
        "  plot_pred(y_pred, y_test, medicine)\n",
        "  print()\n",
        "  plt.close()\n",
        "\n",
        "\n",
        "\n",
        "  # Return the updated DataFrame\n",
        "  return df_scores\n"
      ],
      "metadata": {
        "id": "FIFCrYKt8I0L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_agg_clusters_4[df_agg_clusters_4['HOSPI_CODE_UCD'] == '3400892088310']"
      ],
      "metadata": {
        "id": "zu2pjr4pSVuf",
        "outputId": "d3eba656-4202-4162-bd05-30f7d109739c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [index, HOSPI_CODE_UCD, QUANTITY, N_UFS, DATE, N_ETB, POPULATION, P_MEDICAL, PN_MEDICAL, LIT_HC, LIT_HP, SEJ_MCO, SEJ_HAD, SEJ_PSY, SEJ_SSR, SEJ_SLD, TREND, SEASONAL, RESID, MONTH_1, MONTH_2, MONTH_3, MONTH_4, MONTH_5, MONTH_6, MONTH_7, MONTH_8, MONTH_9, MONTH_10, MONTH_11, MONTH_12, YEAR_2016, YEAR_2017, YEAR_2018, YEAR_2019, HOSPI_HOSPI_1, HOSPI_HOSPI_2, HOSPI_HOSPI_3, HOSPI_HOSPI_4, ID_SITE_RATTACHE, CLUSTER]\n",
              "Index: []\n",
              "\n",
              "[0 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89d84a7b-91bd-4441-973e-b6fa732eb55d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>HOSPI_CODE_UCD</th>\n",
              "      <th>QUANTITY</th>\n",
              "      <th>N_UFS</th>\n",
              "      <th>DATE</th>\n",
              "      <th>N_ETB</th>\n",
              "      <th>POPULATION</th>\n",
              "      <th>P_MEDICAL</th>\n",
              "      <th>PN_MEDICAL</th>\n",
              "      <th>LIT_HC</th>\n",
              "      <th>...</th>\n",
              "      <th>YEAR_2016</th>\n",
              "      <th>YEAR_2017</th>\n",
              "      <th>YEAR_2018</th>\n",
              "      <th>YEAR_2019</th>\n",
              "      <th>HOSPI_HOSPI_1</th>\n",
              "      <th>HOSPI_HOSPI_2</th>\n",
              "      <th>HOSPI_HOSPI_3</th>\n",
              "      <th>HOSPI_HOSPI_4</th>\n",
              "      <th>ID_SITE_RATTACHE</th>\n",
              "      <th>CLUSTER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>0 rows × 41 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89d84a7b-91bd-4441-973e-b6fa732eb55d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-89d84a7b-91bd-4441-973e-b6fa732eb55d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-89d84a7b-91bd-4441-973e-b6fa732eb55d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_prediction_scores = pd.DataFrame(columns=['HOSPI_CODE_UCD', 'R2', 'RMSE', 'MAE', 'MAPE'])\n",
        "\n",
        "for medicine in medicines:\n",
        "  if medicine == '3400891996128':\n",
        "    # Create the new row as a DataFrame\n",
        "    new_row = pd.DataFrame({'HOSPI_CODE_UCD': ['CODE_UCD_'+str(medicine)],\n",
        "                            'R2': [0],\n",
        "                            'RMSE': [0],\n",
        "                            'MAE': [0],\n",
        "                            'MAPE': [0]})\n",
        "\n",
        "    # Append the new row to the DataFrame\n",
        "    df_scores = pd.concat([df_scores, new_row], ignore_index=True)\n",
        "  else:\n",
        "    df_prediction_scores = test_1_baseline(df_agg_clusters_4.drop(['CLUSTER'], axis = 1), medicine, df_prediction_scores)\n",
        "\n",
        "df_prediction_scores"
      ],
      "metadata": {
        "id": "HFCpKbfYBOZJ",
        "outputId": "302384ff-b801-451b-aef1-282472700cb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Medicine:3400892088310\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-9e30b7a90aa0>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdf_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_row\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdf_prediction_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_1_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_agg_clusters_4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CLUSTER'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedicine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_prediction_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdf_prediction_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-11a6837383d1>\u001b[0m in \u001b[0;36mtest_1_baseline\u001b[0;34m(df, medicine, df_scores)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m# Split the data into training and testing sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   X_train, X_test, y_train, y_test = train_test_split(X, y,\n\u001b[0m\u001b[1;32m     19\u001b[0m                                                       \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                                       random_state = 42)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2563\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2237\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_2_clustering(df, df_scores, medicines):\n",
        "\n",
        "  for cluster in df.CLUSTER.unique():\n",
        "    print()\n",
        "    print(100*'-')\n",
        "    print(f'Cluster: {cluster}')\n",
        "\n",
        "    # Perform the train-test split with shuffled samples\n",
        "    X = df[df['CLUSTER'] == cluster].drop(['DATE', 'QUANTITY', 'CLUSTER', 'QUANTITY_MA', 'TREND', 'SEASONAL', 'RESID'], axis=1).copy().values\n",
        "    y = df[df['CLUSTER'] == cluster]['QUANTITY'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.2, shuffle = True)\n",
        "    print(f'Size of data set: {len(X_train) + len(X_test)}')\n",
        "    print(f'Size of training set: {len(X_train)}')\n",
        "    print(f'Size of test set: {len(X_test)}')\n",
        "\n",
        "    df_test = pd.DataFrame(X_test, columns = df.drop(['DATE', 'QUANTITY', 'CLUSTER', 'QUANTITY_MA', 'TREND', 'SEASONAL', 'RESID'], axis=1).copy().columns)\n",
        "    df_test['QUANTITY'] = y_test\n",
        "\n",
        "\n",
        "    # Define the parameter distributions for RandomizedSearchCV\n",
        "    param_grid = {\n",
        "        'max_depth': np.arange(2, 8, 1),\n",
        "        'n_estimators': np.arange(2, max(int(m.ceil(len(X_train)*0.1)),3), 1),\n",
        "        'max_features': ['sqrt', 1, 2]\n",
        "    }\n",
        "\n",
        "    depth_len = param_grid['max_depth'].size\n",
        "    estimators_len = param_grid['n_estimators'].size\n",
        "\n",
        "    print(f'Size of grid search: {depth_len * estimators_len}')\n",
        "\n",
        "    # Create the RandomizedSearchCV object\n",
        "    grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
        "                              param_grid=param_grid,\n",
        "                              scoring = 'neg_mean_absolute_percentage_error',\n",
        "                              cv = 5,\n",
        "                              n_jobs = -1)\n",
        "\n",
        "    ''' >3 : the fold and candidate parameter indexes\n",
        "        are also displayed together with the starting time of the computation.\n",
        "    '''\n",
        "\n",
        "\n",
        "    # Fit the RandomizedSearchCV object to the data\n",
        "    grid_search.fit(X_train[:,1:], y_train)\n",
        "\n",
        "    print(\"Finished training\")\n",
        "\n",
        "    # Get the best estimator\n",
        "    best_estimator = grid_search.best_estimator_\n",
        "\n",
        "    for medicine in df_test.HOSPI_CODE_UCD.unique():\n",
        "      print()\n",
        "      print(100*'-')\n",
        "      print('Medicine:' + str(medicine))\n",
        "\n",
        "      X_test_medicine = df_test[df_test['HOSPI_CODE_UCD'] == medicine].drop(['QUANTITY', 'HOSPI_CODE_UCD'], axis=1).copy().values\n",
        "\n",
        "      scaler = StandardScaler()\n",
        "      X_test_scaled = scaler.fit_transform(X_test_medicine)\n",
        "\n",
        "      y_test_medicine = df_test[df_test['HOSPI_CODE_UCD'] == medicine]['QUANTITY'].copy().values\n",
        "\n",
        "      # Make predictions using the best estimator\n",
        "      y_pred = best_estimator.predict(X_test_scaled)\n",
        "\n",
        "      # Calculate R^2 score\n",
        "      r2 = r2_score(y_test_medicine, y_pred)\n",
        "\n",
        "      # Calculate MAE\n",
        "      mae = mean_absolute_error(y_test_medicine, y_pred)\n",
        "\n",
        "      # Calculate MAPE\n",
        "      mape = mean_absolute_percentage_error(y_test_medicine, y_pred)\n",
        "\n",
        "      # Calculate RMSE\n",
        "      rmse = np.sqrt(mean_squared_error(y_test_medicine, y_pred))\n",
        "\n",
        "      # Print the best parameters, best score, and evaluation metrics\n",
        "\n",
        "      # Print the best parameters, best score, and evaluation metrics\n",
        "      print('Best Parameters: ', grid_search.best_params_)\n",
        "      print('Training Score (MAPE): ', round(grid_search.best_score_, 3))\n",
        "      print(10*'-' + 'Test scores' + 10*'-')\n",
        "      print('R^2 Score:', round(r2, 3))\n",
        "      print('MAE:', round(mae, 3))\n",
        "      print('MAPE:', round(mape, 3))\n",
        "      print('RMSE:', round(rmse, 3))\n",
        "      print()\n",
        "\n",
        "\n",
        "      # Create the new row as a DataFrame\n",
        "      new_row = pd.DataFrame({'CLUSTER': [cluster],\n",
        "                              'HOSPI_CODE_UCD': ['CODE_UCD_'+str(int(medicine))],\n",
        "                              'R2': [r2],\n",
        "                              'RMSE': [rmse],\n",
        "                              'MAE': [mae],\n",
        "                              'MAPE': [mape]})\n",
        "\n",
        "      # Append the new row to the DataFrame\n",
        "      df_scores = pd.concat([df_scores, new_row], ignore_index=True)\n",
        "\n",
        "      plot_pred(y_pred, y_test_medicine, medicine)\n",
        "      print()\n",
        "\n",
        "\n",
        "  # Return the updated DataFrame\n",
        "  return df_scores"
      ],
      "metadata": {
        "id": "t5HDkErJMRXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''df_prediction_scores_agg = pd.DataFrame(columns=[ 'HOSPI_CODE_UCD', 'CLUSTER', 'R2', 'RMSE', 'MAE', 'MAPE'])\n",
        "\n",
        "df_prediction_scores_agg = test_2_clustering(df_agg_clusters, df_prediction_scores_agg, medicines)\n",
        "\n",
        "df_prediction_scores_agg'''"
      ],
      "metadata": {
        "id": "jXkTnnRzjW47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''df_prediction_scores_pca = pd.DataFrame(columns=[ 'HOSPI_CODE_UCD', 'CLUSTER', 'R2', 'RMSE', 'MAE', 'MAPE'])\n",
        "\n",
        "df_prediction_scores_pca = test_2_clustering(df_clustered_pca, df_prediction_scores_pca, medicines)\n",
        "\n",
        "df_prediction_scores_pca'''"
      ],
      "metadata": {
        "id": "ijVxQZCFSeto"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}